{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 7　実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 7.1　GPUとGPGPU\n",
    "画像に対するGPU利用と比べて自然言語処理分野ではGPU利用が難しかったが、  \n",
    "近年GPUを利用するための手法が発展してきた。\n",
    "\n",
    "GPU利用には計算の並列化が重要であり、その代表はミニバッチ化である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 7.2　RNNにおけるミニバッチ化\n",
    "自然言語処理においてミニバッチ化を妨げていた問題は  \n",
    "入力文や出力文の長さが一定でないということである。\n",
    "\n",
    "古くから文長ごとにデータセットを分割する手法はあったが、これは無作為抽出を不可能にするため  \n",
    "モデルの予測能力に深刻な悪影響を与えることがある。\n",
    "\n",
    "そこで考えられたのが padding を文へ適用することで、  \n",
    "nullなど事前に定めた特殊な単語を付加することで文長を揃え並列計算を効率化する。    \n",
    "ただし、全ての文がミニバッチ中の最大長に揃えられることになるため、計算量そのものは増大する。\n",
    "\n",
    "また、文長によりソートすることで並列計算における無駄な分岐を減らすことができるので、  \n",
    "これも計算速度向上に寄与する。  \n",
    "\n",
    "paddngによる計算量増大を軽減するためにミニバッチごとに文長を選択して  \n",
    "それぞれの文長に合わせた計算グラフを事前に準備することで計算時間を減らすテクニックがあり、  \n",
    "これをバケッティング（bucketing）という。  \n",
    "ただし、文長の種類が多いと計算グラフを事前準備する意味は失われていく。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 多層のRNNの高速化\n",
    "RNNにおいて時刻 $t$ における $k$ 番目の層の出力を $\\mathbf{h}_{t}^{(k)}$ と表記する。  \n",
    "時刻 $t$ または層の番号 $k$ が一致する２つの出力は依存性が存在するために並列計算できないが、  \n",
    "$t$ と $k$ の両方が異なれば依存関係が存在しないため、理論的には並列計算可能である。\n",
    "\n",
    "J.Appleyard et al. [Optimizing Performance of Recurrent Neural Networks on GPUs](https://arxiv.org/abs/1604.01946) arXiv:1604.01946 [cs.LG] 2016.  \n",
    "ではRNNに種々の計算効率改善策を実装し、最大11倍の高速化を果たしたと報告されている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 持続性再帰ニューラルネット （persistent RNN）\n",
    "RNNの隠れ状態ベクトルを $\\mathbf{h} \\in \\mathbb{R}^{D}$、バッチ数を $B$ とする。  \n",
    "このとき隠れ状態ベクトルとパラメータ行列の積の時間計算量は $O(BD^{2})$、  \n",
    "GPUにおけるメモリの消費量は $O(D^{2})$ である。\n",
    "\n",
    "計算中プロセッサ上のレジスタに行列を保持して読み込み時間を抑える  \n",
    "持続性再帰ニューラルネットという手法が提案されている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 木構造再帰ニューラルネットのミニバッチ化\n",
    "Tree-RNNの単純なミニバッチ化は困難である。\n",
    "\n",
    "再帰的な伝播計算を、スタックを用いる直列的な計算に変換することを考える。  \n",
    "各ノードに木の帰りがけ順に番号を振り、番号の小さい順にたどりながら処理を行うこととする。\n",
    "\n",
    "葉ノードに対して埋め込みベクトルを計算する操作を $\\Lambda$、  \n",
    "各ノードに対して２つの子ノードの隠れ状態ベクトル $\\mathbf{h}_{L}, \\mathbf{h}_{R}$ から  \n",
    "親ノードの隠れ状態ベクトル $\\mathbf{h}_{P}$ を計算する操作を $\\Psi$ とする。\n",
    "\n",
    "帰りがけ順にノードをたどるとき、葉ノードで $\\Lambda$ を、それ以外のノードで $\\Psi$ を行えばよい。  \n",
    "この操作はスタックを利用した木構造の走査と見なすことができるので、  \n",
    "$\\Lambda$ では計算結果をプッシュし、 $\\Psi$ ではポップ操作で２データを読み込み計算結果をプッシュする。\n",
    "\n",
    "各ステップでどの変数に $\\Lambda, \\Psi$ いずれの操作を行うかがわかれば並列化可能である。  \n",
    "これは上記のようなスタックの情報 $\\{ \\mathbf{h}_{i} \\}$ を保持すれば可能である。\n",
    "\n",
    "文長 $I$ について $\\{\\mathbf{h}_{i}\\}$ の大きさは $2I-1$、各要素は $\\mathbf{h}_{i} \\in \\mathbb{R}^{D}$ であり、  \n",
    "各ステップごとに複製が必要であるから、前向き計算で $O(I^{2}D)$ のメモリを消費する。  \n",
    "これはシンスタック（thin stack）により空間計算量を $O(ID)$ まで減らすことができる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 7.3　無作為抽出\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
