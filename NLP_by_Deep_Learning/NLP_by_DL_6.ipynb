{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 6　汎化性能を向上させる技術\n",
    "---\n",
    "注：\n",
    " - ６章の内容は手法の羅列のみなので、詳細や実装は別の資料を参考にすることを推奨する。\n",
    " - 数式の詳細や実装についてはすでに他のnotebookで扱ったので、ここでは深入りしていない。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 6.1　汎化誤差の分解\n",
    "汎化誤差は以下の３つに分解して考えることができる。\n",
    "\n",
    " - 近似誤差：モデルの表現力不足により、パラメータを増やすなどして自由度を上げると改善\n",
    " - 推定誤差：訓練データの偏りにより、訓練データを増やすか自由度を下げると改善\n",
    " - 最適化誤差：最適化アルゴリズムにより、別のアルゴリズムを試すと改善することがある\n",
    "\n",
    "訓練データでの誤差が大ならば近似誤差や最適化誤差を考え、  \n",
    "評価データや開発データでの誤差が大ならば推定誤差が大きいと判断できる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 6.2　推定誤差低減に効く手法\n",
    "推定誤差を防ぐ手法は正則化（regularization）と呼ばれる。  \n",
    "これらの手法は一般に\n",
    " - 訓練データの差が予測結果に大きく影響することを防ぐため、ばらつきを抑える\n",
    " - 事前知識を用いて特定の仮定を置く\n",
    "\n",
    "という点が共通する。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### L2正則化 （L2 regularization）\n",
    "パラメータの値の大きさに罰則を与える正則化項を導入する。\n",
    "\n",
    "\\begin{align*}\n",
    "L(\\theta) + \\frac{\\lambda}{2}||\\theta||^{2}\n",
    "\\end{align*}\n",
    "\n",
    "ここで $\\lambda$ は正則化の強さを調整するパラメータである。\n",
    "\n",
    "正則化項の偏微分は\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial}{\\partial \\theta} \\frac{\\lambda}{2}||\\theta||^{2} = \\lambda \\theta\n",
    "\\end{align*}\n",
    "\n",
    "であるから、勾配法での更新式は次の通り。\n",
    "\n",
    "\\begin{align*}\n",
    "\\theta^{(k+1)} &= \\theta^{(k)} - \\eta \\partial L(\\theta^{(k)}) - \\eta \\lambda \\theta^{(k)} \\\\\n",
    "&= (1-\\eta \\lambda) \\theta^{(k)} - \\eta \\partial L(\\theta^{(k)})\n",
    "\\end{align*}\n",
    "\n",
    "式より、パラメータの値は $(1-\\eta \\lambda) \\leq 1$ 倍されることがわかる。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### early stopping\n",
    "学習中に性能評価を実施して、改善が見られない場合に学習を早期終了することで過学習を防ぐ手法である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 学習率減衰 （learning rate decay）\n",
    "学習中に性能評価を実施して、改善が見られない場合に更新率を下げる手法である。  \n",
    "　（注：この定義は著者により差があり、改善の有無を見ずに更新率を下げる手法について言われることのほうが多い）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### パラメータ共有 （parameter sharing）\n",
    "ニューラルネット内の複数の要素あるいは複数のネット間で同じパラメータを使用する手法の総称である。  \n",
    "これは学習対象について何らかの共通点があることを仮定しており、  \n",
    "手法の使用にあたっては事前知識を必要とすることに注意が必要である。\n",
    "\n",
    "RNNにおいて入力単語と出力単語のパラメータ行列を共有するのが有名な適用例であり、  \n",
    "性能が向上した例が報告されている。\n",
    "\n",
    "マルチタスク学習でもしばしば適用があり、  \n",
    "複数言語間翻訳でモデルの一部を共有することで性能が改善する例が報告されている。\n",
    "\n",
    "パラメータ共有に類似した手法としてパラメータ結束（parameter tying）があり  \n",
    "２つのパラメータの差に対して罰則を与えることで近いパラメータを学習させる。  \n",
    "罰則としてはフロベニウスノルム（Frobenius norm）の２乗\n",
    "\n",
    "\\begin{align*}\n",
    "||\\mathbf{W}^{(a)} - \\mathbf{W}^{(b)}||^{2}\n",
    "\\end{align*}\n",
    "\n",
    "などを用いる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 事前学習 （pre-training）\n",
    "別の補助タスクで学習したパラメータを主タスクのニューラルネットの一部として使う手法である。  \n",
    "このうち、学習するときの初期値として使い、主タスクの損失を減らすよう学習させるものを fine tuning という。\n",
    "\n",
    "NLP分野では単語埋め込みベクトルが最も広く使われている例で、  \n",
    "事前学習したパラメータで固定または初期化していることが多い。\n",
    "\n",
    "例えば補助タスクとして一般的な大規模コーパスにより埋め込みベクトルを学習し  \n",
    "主タスクとして目的の特定分野に特化したコーパスにより学習することで  \n",
    "性能向上がみられることがしばしばある。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### アンサンブル法 （ensemble method）\n",
    "複数モデルを組み合わせて予測する手法で、  \n",
    "コミッティマシン（committee machines）やモデル平均化法（model averaging）とも呼ばれる。\n",
    "\n",
    "アンサンブル法はいわばモデルの多数決による予測で、  \n",
    "単独モデルでの予測より正解する確率が高いことが期待できる。\n",
    "\n",
    "類似のものとして、バギング（bootstrap aggregating, bagging）がある。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### ドロップアウト （dropout）\n",
    "訓練時に状態変数の一部をランダムに０に設定する手法である。\n",
    "\n",
    "実装としては、ドロップアウトマスク $\\zeta^{(l)} \\in \\{ 0,1 \\}^{N^{(l)}}$ を用いて\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbf{h}^{(l)} = \\zeta^{(l)} \\odot \\mathbf{h}^{(l-1)}\n",
    "\\end{align*}\n",
    "\n",
    "の計算により出力を加工する。\n",
    "\n",
    "Y.Gal and Z.Ghahramani, [A Theoretically Grounded Application of Dropout in Recurrent Neural Networks](https://arxiv.org/abs/1512.05287) In proc. of NIPS, 2016.  \n",
    "ではベイズ的解釈に基づき、ドロップアウトをパラメータ分布からサンプリング方法ととらえ、  \n",
    "事後分布を変分近似しているとの解釈が与えられている。  \n",
    "\n",
    "この解釈を元に提案された Monte-Carlo Dropout は  \n",
    "予測時に複数の Dropout パターンを試して平均を取る手法で、  \n",
    "単一モデルによる既存手法よりも良い精度を出した。\n",
    "\n",
    "これらの Dropout 手法は、暗にアンサンブル法を適用しているものと解釈される。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 6.3　最適化誤差低減に効く手法\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 初期値設定\n",
    "初期値が同じパラメータは勾配法を適用すると同じく更新されてしまうので、  \n",
    "それぞれの値を違える必要がある。\n",
    "\n",
    "一般にはXavierの初期値やHeの初期値が頻用されている。\n",
    "\n",
    "IRNNはRNNのパラメータ行列（の一部）を単位行列で初期化する手法である。これは\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbf{h}_{t}^{(l)} = a^{(l)} (\\tilde{\\mathbf{W}}^{(l)}\\mathbf{h}_{t}^{(l-1)} + \\mathbf{h}_{t-1}^{(l)} + \\mathbf{b}^{(l)})\n",
    "\\end{align*}\n",
    "\n",
    "のように、ある層から次の層へのショートカットを形成することに等しい。\n",
    "\n",
    "また、忘却ゲートにおけるバイアスパラメータの初期値を１など大きな値にすることも  \n",
    "同様にショートカット形成としての効果がある。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### カリキュラム学習 （curriculum learning）\n",
    "学習過程を複数段階に分け、簡単な概念からはじめて  \n",
    "徐々に複雑な概念ないしタスクを学習させていく手法である。\n",
    "\n",
    "タスクの難易度について仮定または事前知識が必要なものの  \n",
    "複数の分野で有用性が報告されている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 正規化\n",
    "勾配法ではパラメータ同士の関係を考慮しないため、パラメータ間に依存性があると学習が安定しないことがある。\n",
    "\n",
    "ニュートン法は有効であることが知られているが、  \n",
    "パラメータ数の２乗に比例して計算量が増加するために負荷が高い。\n",
    "\n",
    "バッチ正規化（batch normalization）はよく使われる手法で、  \n",
    "ミニバッチ内で計算した平均と分散を用いて入力を正規化する。  \n",
    "予測時には訓練データ中の複数のミニバッチについて求めた平均と分散とで正規化を行う。\n",
    "\n",
    "類似手法に層正規化（layer normalization）があり、各層の隠れ状態ベクトルの要素集合について正規化する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 6.4　超パラメータ選択\n",
    "ハイパーパラメータの選択にはグリッド探索やランダム探索がよく用いられる。  \n",
    "この２者について現在のところ優劣を示す証拠はないので、あなたの信仰に従って選んでよい。\n",
    "\n",
    "ベイズ的最適化（Bayesian optimization; BO）はガウス過程による回帰を用いて  \n",
    "説明変数と目的変数との間で回帰モデルを構築し、  \n",
    "よりよい目的変数の値を与える可能性の高い説明変数を見つける手法である。\n",
    "\n",
    "BOをハイパーパラメータ選択に適用することで、  \n",
    "より良い性能を与える可能性が高く、かつ評価の不確実性が高い候補ほど高い確率で調査できるため  \n",
    "効率の良い探索と選択ができる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "次のnotebookへ続く。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
