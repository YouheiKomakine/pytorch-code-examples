{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Ch.2　ニューラルネットの基礎"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.1　教師あり学習\n",
    "入力変数ベクトル $\\mathbf{x} \\in \\mathcal{X}$、出力変数 $y \\in \\mathcal{Y}$ について  \n",
    "ある変数 $\\mathbf{x}$ が与えられた時に $y$ を予測するモデルを学習することを目的とする。\n",
    "\n",
    "教師あり学習の定義\n",
    "$|\\mathcal{D}|$ 個の訓練事例を $\\mathcal{D} = \\{(\\mathbf{x}^{(n)}, y^{(n)})\\}_{n=1}^{|\\mathcal{D}|}$ としたとき、  \n",
    "訓練データでの誤差（以下の目的関数）を最小化するモデルパラメータ $\\mathbf{\\theta}$ の値を求める手続きを教師あり学習と呼ぶ。\n",
    "\n",
    "\\begin{align*}\n",
    "L(\\mathbf{\\theta}) = \\frac{1}{|\\mathcal{D}|} \\sum_{n=1}^{|\\mathcal{D}|} l_{\\mathbf{\\theta}} (\\mathbf{x}^{(n)}, y^{(n)})\n",
    "\\end{align*}\n",
    "\n",
    "自然言語処理では出力は単語のように離散集合 $\\mathcal{Y} = \\{1, \\ldots, |\\mathcal{Y}| \\}$ であることが多く、分類問題として定式化できる。  \n",
    "分類問題では 0-1損失関数の代理損失（surrogate loss）として、  \n",
    "次の交差エントロピー損失関数と（多クラス）ヒンジ損失関数がよく用いられる。\n",
    "\n",
    "・cross-entropy loss\n",
    "\n",
    "\\begin{align*}\n",
    "l_{\\mathbf{\\theta}}^{\\text{cross-entropy}} \\left( \\mathbf{x}^{(n)}, y^{(n)} \\right) = - \\log \\frac{\\exp ( f_{\\mathbf{\\theta}}( \\mathbf{x}^{(n)}, y^{(n)} ))}{\\sum_{\\tilde{y} \\in \\mathcal{Y}} \\exp ( f_{\\mathbf{\\theta}}(\\mathbf{x}^{(n)}, \\tilde{y}))}\n",
    "\\end{align*}\n",
    "\n",
    "・multiclass hinge loss\n",
    "\n",
    "\\begin{align*}\n",
    "l_{\\theta}^{\\text{hinge}}\\left( \\mathbf{x}^{(n)}, y^{(n)} \\right) = \\max \\left( 0, \\, 1 - f_{\\theta}\\left( \\mathbf{x}^{(n)}, y^{(n)} \\right) + \\max_{\\tilde{y} \\in {\\mathcal{Y} \\\\ \\{y^{(n)}\\}} } f_{\\theta}( \\mathbf{x}^{(n)}, \\tilde{y}) \\right)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "$f_{\\theta}(\\mathbf{x},y)$ は $\\theta$ をパラメータとするスコア関数で、$\\hat{y} = \\operatorname{argmax}_{y} f_{\\theta}(\\mathbf{x}^{(n)}, y)$ を予測として使用することを想定している。  \n",
    "注記なき限りスコア関数はニューラルネットによる実装とする。\n",
    "\n",
    "誤差関数として交差エントロピー、スコア関数 $f_{\\theta}(\\mathbf{x},y)$ を線形モデルとするとき多項ロジスティック回帰という。  \n",
    "交差エントロピー損失関数は以下の条件付き確率モデルを想定し、  \n",
    "その負の対数尤度を想定していると考えることもできる。  \n",
    "\n",
    "\\begin{align*}\n",
    "P_{\\theta}(y|\\mathbf{x}) = \\frac{\\exp ( f_{\\theta} (\\mathbf{x},y))}{\\sum_{\\tilde{y} \\in \\mathcal{Y}} \\exp ( f_{\\theta} ( \\mathbf{x}, \\tilde{y}))}\n",
    "\\end{align*}\n",
    "\n",
    "交差エントロピー損失関数は、真の分布 $P^{*}_{\\theta}(y|\\mathbf{x})$ とモデル $P_{\\theta}(y|\\mathbf{x})$ との距離を表す交差エントロピーを  \n",
    "訓練データで経験近似していることに相当することからそう呼ばれる。\n",
    "\n",
    "ソフトマックス関数\n",
    "\n",
    "\\begin{align*}\n",
    "\\operatorname{softmax}(\\mathbf{o})_{y} = \\frac{\\exp (o_{y})}{\\sum_{\\tilde{y} \\in \\mathcal{Y}} \\exp (o_{y})}\n",
    "\\end{align*}\n",
    "\n",
    "を用いると、上の式は\n",
    "\n",
    "\\begin{align*}\n",
    "P_{\\theta}(y|\\mathbf{x}) = \\operatorname{softmax}(\\mathbf{o})_{y}\n",
    "\\end{align*}\n",
    "\n",
    "と書くことができる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
