{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 5　応用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 5.1　機械翻訳\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 統計翻訳とニューラル翻訳\n",
    "ある言語の文章を多言語の文章に翻訳する、人手を介さない方法論を機械翻訳（machine translation）と総称する。  \n",
    "ルールベース翻訳、用例ベース翻訳、統計翻訳（statistical machine translation）などの方法論があり、  \n",
    "系列変換モデルを利用した機械翻訳はニューラル翻訳（neural machine translation）と呼ばれる場合が多い。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### NMTの典型的なモデル構成\n",
    "[OpenNMT](http://opennmt.net/)（旧seq2seq-attn）が現在ベースラインと認識されるモデルの代表である。  \n",
    "この中のモデルの１つについて取り上げる。\n",
    "\n",
    "符号化器再帰層に２層bi-directional LSTMを使うとする。\n",
    "$\\Psi(\\cdot)$ をLSTMの処理を表す関数とすると、擬似コードは次の通り。\n",
    "\n",
    "\\begin{align*}\n",
    "&\\text{Input: } \\, X = (x_{i})_{i=1}^{I} \\\\\n",
    "&\\text{begin} \\\\\n",
    "&\\hspace{5pt}  h_{0}^{fw1} \\leftarrow 0, h_{0}^{fw2} \\leftarrow 0, h_{I+1}^{bw1} \\leftarrow 0, h_{I+1}^{bw2} \\leftarrow 0 \\\\\n",
    "&\\hspace{5pt}  \\bar{X} \\leftarrow E^{s}X \\\\\n",
    "&\\hspace{5pt}  \\text{for} \\, i \\leftarrow 1 \\, \\text{to} \\, I \\, \\text{do} \\\\\n",
    "&\\hspace{10pt} h_{i}^{fw1} \\leftarrow \\Psi^{fw1}(\\bar{x}_{i},h_{i-1}^{fw1}) \\\\\n",
    "&\\hspace{10pt} h_{i}^{fw2} \\leftarrow \\Psi^{fw2}(h_{i}^{fw1},h_{i-1}^{fw2}) \\\\\n",
    "&\\hspace{5pt} \\text{end} \\\\\n",
    "&\\hspace{5pt} \\text{for} \\, i \\leftarrow 1 \\, \\text{to} \\, I \\, \\text{do} \\\\\n",
    "&\\hspace{10pt} i' \\leftarrow I+1-i \\\\\n",
    "&\\hspace{10pt} h_{i'}^{bw1} \\leftarrow \\Psi^{bw1}(\\bar{x}_{i'},h_{i'+1}^{bw1}) \\\\\n",
    "&\\hspace{10pt} h_{i'}^{bw2} \\leftarrow \\Psi^{bw2}(h_{i'}^{bw1},h_{i'+1}^{bw2}) \\\\\n",
    "&\\hspace{10pt} h_{i'}^{s} = h_{i'}^{fw2} + h_{i'}^{bw2} \\\\\n",
    "&\\hspace{5pt} \\text{end} \\\\\n",
    "&\\text{end} \\\\\n",
    "&\\text{Output: } \\, H^{s}=(h_{i}^{s})_{i=1}^{I}, h_{I}^{fw1}, h_{I}^{fw2}, h_{1}^{bw1}, h_{1}^{bw2} \\\\\n",
    "\\end{align*}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、復号化再帰層に２層LSTMを使うものとすると、擬似コードは次の通り。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "評価時の復号化処理は一般にビーム探索を用いて処理を行うことが多い。\n",
    "学習後に未知データを評価する際の復号化処理を擬似コードで表したものは次の通り。\n",
    "（これはK=1のビーム探索と等価なアルゴリズムである。）"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
