{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TD学習 (Temporal Difference Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source : Richard S. Sutton and Andrew G.Barto, 「強化学習」"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 強化学習の枠組み"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "強化学習の枠組みは、学習と意思決定を行う「エージェント」と  \n",
    "それ以外のすべてから構成される「環境」の相互作用として表される。  \n",
    "  \n",
    "離散的な時間ステップ　$t=0,1,...$のあるステップtにおいて、  \n",
    "エージェントは環境から状態$s_{t}$を受け取り、行動$a_{t}$を選択する。  \n",
    "  \n",
    "このとき、状態$s_{t}$から行動$a_{t}$への写像はエージェントの方策（policy）と呼ばれ、$\\pi(s,a)$で表される。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、エージェントは、最終的に受け取る報酬を最大化することを目標として学習する。  \n",
    "一般的には期待収益（expected return）を最大化するように設定される。  \n",
    "  \n",
    "各時間ステップtに受け取る報酬を$r_{t}$とするとき、  \n",
    "最も単純な場合には、収益$R_{t}$は  \n",
    "\n",
    "\\begin{align*}\n",
    "R(t) = r_{t+1} + r_{t+2} + ... + r_{T}\n",
    "\\end{align*}\n",
    "\n",
    "として表される。ここでTは最終時間ステップである。（相互作用が離散的な場合）  \n",
    "  \n",
    "連続タスクにおいてはT=∞となりR(t)が発散しうるため、割引収益  \n",
    "\n",
    "\\begin{align*}\n",
    "R_{t} &= r_{t+1} + \\gamma r_{t+2} + \\gamma^{2} r_{t+3} + ... \\\\  \n",
    "　　　&= \\sum_{k=0}^{\\infty}\\gamma^{k} r_{t+k+1} \n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "\n",
    "を最大化するようにa(t)を選択する。  \n",
    "ただし、γは割引率と呼ばれるパラメータで(0<=γ<=1)である。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般的な強化学習アルゴリズムは価値関数に基づく評価を行っている。  \n",
    "方策πのもとでの状態sの価値Vπ(s)は、MDP（マルコフ決定過程）では  \n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "V^{\\pi}(s) &= E_{\\pi}\\{R_{t} | s_{t}=s\\} \\\\\n",
    "&= E_{\\pi}\\{ \\sum_{k=0}^{\\infty}\\gamma^{k}r_{t+k+1}|s_{t}=s\\}\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "と表される。関数 $ V^{\\pi} $を方策πに対する状態価値観数と呼ぶ。\n",
    "  \n",
    "同様に、方策πのもとで状態sにおいて行動aを取ることの価値を $Q^{\\pi}(s,a)$で表し、  \n",
    "状態sで行動aを取り、その後に方策πに従った期待報酬として次のように定義する。  \n",
    "\n",
    "\\begin{align*}\n",
    "Q^{\\pi}(s,a) &= E_{\\pi}\\{R_{t}|s_{t}=s, a_{t}=a\\} \\\\\n",
    "&= E_{\\pi}\\{\\sum_{k=0}^{\\infty}\\gamma^{k}R_{t+k+1}|s_{t}=s, a_{t}=a\\}\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "任意のs,aが与えられたときの次に可能な各状態s'の確率を遷移確率と呼ぶ。  \n",
    "\n",
    "\\begin{align*}\n",
    "P^{a}_{ss'} = Pr\\{s_{t+1}=s'| s_{t}=s, a_{t}=a\\}\n",
    "\\end{align*}\n",
    "\n",
    "  \n",
    "同様にして、次の報酬の期待値を次のように表す。\n",
    "\n",
    "\\begin{align*}\n",
    "R^{a}_{ss'}=E\\{r_{t+1}| s_{t}=s, a_{t}=a, s_{t+1}=s'\\}\n",
    "\\end{align*}\n",
    "\n",
    "  \n",
    "    \n",
    "強化学習と動的計画法で使われている価値関数は、  \n",
    "任意の方策πと状態sに対して、sの価値と可能な後続状態群の価値との間に  \n",
    "以下の整合性条件（consistency condition）がなりたち、これを$V^{\\pi}$に対するBellman方程式という。  \n",
    "  \n",
    "\n",
    "\\begin{align*}\n",
    "V^{\\pi}(s) &= E_{\\pi}\\{R_{t} | s_{t}=s\\} \\\\\n",
    "&= E_{\\pi}\\{ \\sum_{k=0}^{\\infty}\\gamma^{k}r_{t+k+1}|s_{t}=s\\} \\\\\n",
    "&= E_{\\pi}\\{r_{t+1}+ \\gamma\\sum_{k=0}^{\\infty}\\gamma^{k}r_{t+k+2}|s_{t}=s\\} \\\\\n",
    "&= \\sum_{a}\\pi(s,a)\\sum_{s'}P^{a}_{ss'} [ R^{a}_{ss'} + \\gamma E_{\\pi} \\{ \\sum_{k=0}^{\\infty}\\gamma^{k}r_{t+k+2}|s_{t+1}=s'\\} ] \\\\\n",
    "&= \\sum_{a}\\pi(s,a)\\sum_{s'}P^{a}_{ss'}[R^{a}_{ss'}+\\gamma V^{\\pi}(s')]\n",
    "\\end{align*}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "いま、すべての状態に対して、方策πの期待収益がπ'よりも良いか同じであるなら、  \n",
    "πはπ'よりも良いか、同じであると定義する。  \n",
    "つまり、すべての $ s \\in S $ に対して、$ V^{\\pi}(s) \\leqq V^{\\pi'}(s) $ であるなら、その時に限り $\\pi \\leqq \\pi'$である。\n",
    "  \n",
    "これが１つの最適方策であり、すべての最適方策を$\\pi^{*}$と記す。  \n",
    "最適方策群は最適状態価値関数 $V^{*}(s) = \\max_{\\pi}V^{\\pi}(s)$ を共有する。    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同様に、最適方策群は最適行動価値関数 $Q^{*}(s,a)=\\max_{\\pi}Q^{\\pi}(s,a)$ を共有する。  \n",
    "$V^{*}$を用いて$Q^{*}$を次のように書くことができる。  \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "Q^{*}(s,a)=E\\{r_{t+1}+\\gamma V^{*}(s_{t+1})|s_{t}=s,a_{t}=a\\}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$V^{*}$に対するBellman方程式を、Bellman最適方程式という。  \n",
    "  \n",
    "\n",
    "\\begin{align*}\n",
    "V^{*}(s) &= \\max_{a \\in A(s)}Q^{\\pi^{*}}(s,a) \\\\\n",
    "&= \\max_{a}E_{\\pi^{*}}\\{R_{t} | s_{t}=s\\} \\\\\n",
    "&= \\max_{a}E_{\\pi^{*}}\\{ \\sum_{k=0}^{\\infty}\\gamma^{k}r_{t+k+1}|s_{t}=s\\} \\\\\n",
    "&= \\max_{a}E_{\\pi^{*}}\\{r_{t+1}+ \\gamma\\sum_{k=0}^{\\infty}\\gamma^{k}r_{t+k+2}|s_{t}=s\\} \\\\\n",
    "&= \\max_{a}E\\{r_{t+1}+\\gamma V^{*}(s_{t+1})|s_{t}=s,a_{t}=a\\} \\\\\n",
    "&= \\max_{a}\\sum_{s'}P^{a}_{ss'}[R^{a}_{ss'}+\\gamma V^{*}(s')]\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "$Q^{*}$に対するBellman最適方程式は次の通り。\n",
    "\n",
    "\\begin{align*}\n",
    "Q^{*}(s) &= E\\{r_{t+1}+\\gamma \\max_{a'}Q^{*}(s_{t+1},a')|s_{t}=s,a_{t}=a\\} \\\\\n",
    "&= \\sum_{s'}P^{a}_{ss'}[R^{a}_{ss'}+\\gamma \\max_{a'} Q^{*}(s',a')]\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TD学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TD法は経験を用いて予測問題を解決し、方策πに従って経験をいくつか得ることで  \n",
    "$V^{\\pi}$ の推定値$V$を更新する手法の一つである。  \n",
    "  \n",
    "最も単純なTD法はTD(0)と呼ばれ、以下のようになる。\n",
    "\n",
    "\\begin{align*}\n",
    "V(s_{t}) \\leftarrow V(s_{t}) + \\alpha [ r_{t+1}+\\gamma V(s_{t+1}) - V(s_{t})]\n",
    "\\end{align*}\n",
    "\n",
    "ここで$\\alpha$はステップサイズパラメータである。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$V^{\\pi}$に対するBellman方程式より\n",
    "\n",
    "\\begin{align*}\n",
    "V^{\\pi}(s) &= E_{\\pi}\\{R_{t} | s_{t}=s\\} \\\\\n",
    "&= E_{\\pi}\\{r_{t+1}+ \\gamma\\sum_{k=0}^{\\infty}\\gamma^{k}r_{t+k+2}|s_{t}=s\\} \\\\\n",
    "\\therefore V^{\\pi}(s) &= E_{\\pi}\\{r_{t+1}+ \\gamma V^{\\pi}(s_{t+1})|s_{t}=s \\}\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "としたとき、モンテカルロ法は前者の推定値を、動的計画法は後者の推定値を目標とする。  \n",
    "TD法は両者を融合させたものである。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テーブル型 TD(0) アルゴリズム\n",
    "Algorithm\n",
    ">$V(s)$を任意に初期化し、$\\pi$を評価対象の方策に初期化する  \n",
    ">各エピソードに対して繰り返し：  \n",
    ">　　$s$を初期化  \n",
    ">　　エピソードの各ステップに対して繰り返し：  \n",
    ">　　　　$ a \\leftarrow s $に対して$\\pi$で与えられる行動  \n",
    ">　　　　行動$a$を取り、報酬$r$と次状態$s'$を観測する  \n",
    ">　　　　$V(s) \\leftarrow V(s) + \\alpha[r+\\gamma V(s')-V(s)]$  \n",
    ">　　　　$s \\leftarrow s'$  \n",
    ">　　$s$が終端状態ならば繰り返しを終了  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このTD予測法を制御問題に適用する方法について考える。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sarsa : 方策オン型TD制御\n",
    "行動価値関数を学習するためにTD法を用いる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm\n",
    ">$Q(s,a)$を任意に初期化  \n",
    ">各エピソードに対して繰り返し：  \n",
    ">　　$s$を初期化  \n",
    ">　　$Q$から導かれる方策（εグリーディ方策など）を用いて、$s$で取る行動$a$を選択する  \n",
    ">　　エピソードの各ステップに対して繰り返し：  \n",
    ">　　　　行動$a$を取り、報酬$r$と次状態$s'$を観測する  \n",
    ">　　　　$Q$から導かれる方策を用いて、$s'$での行動$a'$を選択する  \n",
    ">　　　　$Q(s,a) \\leftarrow Q(s,a) + \\alpha[r+\\gamma Q(s',a')-Q(s,a)]$  \n",
    ">　　　　$s \\leftarrow s'; a \\leftarrow a';$  \n",
    ">　　$s$が終端状態ならば繰り返しを終了 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "＊エージェントと環境との相互作用は離散的であり、エピソード的タスク群に分解されること、  \n",
    "　および行動の集合Aと状態の集合Sは有限の要素しか持たず、  \n",
    "　その数は学習開始時に既知であることを仮定する。  \n",
    "＊また、テーブル型TD(0)アルゴリズムとして実装しており、  \n",
    "　state(i) | i=0~nが一次元的に並べられることを前提としている。  \n",
    "　policyとしてはe-greedyを用いる。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Q_table_function(object):\n",
    "    def __init__(self, state_space_size, action_space_size,\n",
    "                 learning_rate=0.01, discount_rate=0.95, initial_value=1,random_initial_value=True,\n",
    "                 decay_learning_rate=1):\n",
    "        self.state_space_size = state_space_size\n",
    "        self.action_space_size = action_space_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_rate = discount_rate\n",
    "        self.initial_value = initial_value\n",
    "        self.random_initial_value = random_initial_value\n",
    "        self.decay_learning_rate = decay_learning_rate\n",
    "\n",
    "        if self.random_initial_value:\n",
    "            self.q_table = np.random.rand(self.state_space_size, self.action_space_size) * self.initial_value\n",
    "        else:\n",
    "            self.q_table = np.ones((self.state_space_size, self.action_space_size), dtype=float64) * self.initial_value\n",
    "\n",
    "        self.last_state = None\n",
    "        self.last_action = None\n",
    "    \n",
    "    def estimate_q_value(self, state, action=None):\n",
    "        self.last_state, self.last_action = state, action\n",
    "        if action is None:\n",
    "            return self.q_table[state]\n",
    "        else:\n",
    "            return self.q_table[state][action]\n",
    "    \n",
    "    def update_q_table(self, reward, next_state, next_action,\n",
    "                       last_state=None, last_action=None):\n",
    "        last_state = self.last_state if last_state is None else last_state\n",
    "        last_action = self.last_action if last_action is None else last_action\n",
    "\n",
    "        delta = reward + self.discount_rate * self.estimate_q_value(next_state, next_action) \\\n",
    "                - self.estimate_q_value(last_state, last_action)\n",
    "        self.q_table[state][action] = self.q_table[state][action] + self.learning_rate * delta\n",
    "\n",
    "    def decay_learning_rate_value(self, decay_rate=None):\n",
    "        decay_rate = self.decay_learning_rate if decay_rate is None else decay_rate\n",
    "        if 0<=decay_rate<=1:\n",
    "            self.learning_rate = self.learning_rate * decay_rate\n",
    "\n",
    "    def save_q_table(self):\n",
    "        return self.q_table\n",
    "\n",
    "    def load_q_table(self, q_table=None):\n",
    "        if q_table is not None:\n",
    "            self.q_table = q_table\n",
    "\n",
    "    def reset(self, reset_q_table=True, learning_rate=None, discount_rate=None, decay_learning_rate=None):\n",
    "        if reset_q_table:\n",
    "            if self.random_initial_value:\n",
    "                self.q_table = np.random.rand(self.state_space_size, self.action_space_size) * initial_value\n",
    "            else:\n",
    "                self.q_table = np.ones((self.state_space_size, self.action_space_size), dtype=float64) * initial_value\n",
    "        self.learning_rate = learning_rate if learning_rate is not None else self.learning_rate\n",
    "        self.discount_rate = discount_rate if discount_rate is not None else self.discount_rate\n",
    "        self.decay_learning_rate = decay_learning_rate if decay_learning_rate is not None else self.decay_learning_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class Policy_e_greedy(object):\n",
    "    def __init__(self, state_space_size, action_space_size,\n",
    "                 action_count_list=None,\n",
    "                 initial_play_count=None, epsilon=0.1, min_choose=1):\n",
    "        self.state_space_size = state_space_size\n",
    "        self.action_space_size = action_space_size\n",
    "        self.total_play_count = 0\n",
    "        self.min_choose = min_choose\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "        self.last_state = None\n",
    "        self.last_action = None\n",
    "\n",
    "        # self.action_count_list[action] = number of [action] is choosed\n",
    "        if action_count_list is None:\n",
    "            self.action_count_list = np.zeros(self.action_space_size, dtype=int)\n",
    "        else:\n",
    "            self.action_count_list = action_count_list\n",
    "        if initial_play_count is not None:\n",
    "            self.total_play_count = initial_play_count\n",
    "\n",
    "    def choose_act_greedy(self, state, value_table):\n",
    "        index_of_less_selected = np.where(self.action_count_list)\n",
    "        if index_of_less_selected[0].size == 0:\n",
    "            max_index = np.where(value_table == value_table.max())\n",
    "            action = np.random.choice(max_index[0], 1)\n",
    "        else:\n",
    "            action = int(np.random.choice(index_of_less_selected, 1))\n",
    "\n",
    "    def choose_act(self, state, update_flag=True, epsilon=None):\n",
    "        epsilon = self.epsilon if epsilon is None else epsilon\n",
    "        if np.random.choice([1, 0], p=[epsilon, 1-epsilon]):            \n",
    "            action = int(np.random.choice(range(action_space_size)))\n",
    "        else:\n",
    "            action = self.choose_act_greedy(state)\n",
    "\n",
    "        self.last_state, self.last_action = state, action\n",
    "        if update_flag:\n",
    "            self.total_play_count += 1\n",
    "            self.action_count_list[action] += 1\n",
    "        \n",
    "        return action\n",
    "\n",
    "    def save_record(self):\n",
    "        return self.action_count_list, self.total_play_count\n",
    "    \n",
    "    def load_record(self, action_count_list=None, total_play_count=None):\n",
    "        self.action_count_list = action_count_list if action_count_list is not None else self.action_count_list\n",
    "        self.total_play_count = total_play_count if total_play_count is not None else self.total_play_count\n",
    "    \n",
    "    def reset_record(self, reset_count=True, reset_last=True):\n",
    "        if reset_count:\n",
    "            self.total_play_count = 0\n",
    "            self.action_count_list = np.zeros(self.action_space_size, dtype=int)\n",
    "        if reset_last:\n",
    "            self.last_state = None\n",
    "            self.last_action = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Agent_SARSA(object):\n",
    "    def __init__(self, state_space_size, action_space_size,\n",
    "                 state_function, q_function=None, policy_function=None,\n",
    "                 learning_rate=0.01, discount_rate=0.95, \n",
    "                 initial_value=1, random_initial_value=True, decay_learning_rate=1,\n",
    "                 action_count_list=None, initial_play_count=None, epsilon=0.1, min_choose=1):\n",
    "        self.state_space_size = state_space_size\n",
    "        self.action_space_size = action_space_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_rate = discount_rate\n",
    "        self.initial_value = initial_value\n",
    "        self.random_initial_value = random_initial_value\n",
    "        self.decay_learning_rate = decay_learning_rate\n",
    "        self.action_count_list = action_count_list\n",
    "        self.initial_play_count = initial_play_count\n",
    "        self.epsilon = epsilon\n",
    "        self.min_choose = min_choose\n",
    "\n",
    "        self.total_play_count = 0\n",
    "        self.last_state = None\n",
    "        self.last_action = None\n",
    "\n",
    "        self.state_function = state_function\n",
    "\n",
    "        if q_function is None:\n",
    "            self.q_function = Q_table_function(self.state_space_size, self.action_space_size,\n",
    "                                               self.learning_rate, self.discount_rate, self.initial_value,\n",
    "                                               self.random_initial_value, self.decay_learning_rate)\n",
    "        else:\n",
    "            self.q_function = q_function\n",
    "\n",
    "        if policy_function is None:\n",
    "            self.policy_function = Policy_e_greedy(self.state_space_size, self.action_space_size,\n",
    "                                                   self.action_count_list, self.initial_play_count,\n",
    "                                                   self.epsilon, self.min_choose)\n",
    "        else:\n",
    "            self.policy_function = policy_function\n",
    "\n",
    "\n",
    "    def act(self, state, update_flag=True):\n",
    "        action = self.policy_function.choose_act(state, update_flag=update_flag)\n",
    "        self.last_state, self.last_action = state, action\n",
    "        return action\n",
    "\n",
    "    def observe_state(action=None):\n",
    "        # state_function must return (reward, next_state, episode_end_flag)\n",
    "        return self.state_function.return_next(action)\n",
    "\n",
    "\n",
    "    def learning_step(self, action, update_flag=True):\n",
    "        reward, next_state, episode_end_flag = self.observe_state(action)\n",
    "        if episode_end_flag:\n",
    "            next_action = -1\n",
    "        else:\n",
    "            next_action = self.act(next_state, update_flag)\n",
    "        if update_flag:\n",
    "            self.q_function.update_q_table(reward, next_state, next_action,\n",
    "                                           self.last_state, self.last_action)\n",
    "        return reward, next_state, next_action, episode_end_flag\n",
    "\n",
    "    def learn(self, episode_num, maximum_trial_per_episode=1000, \n",
    "              save_flag=True, update_flag=True, reset_when_finished=False):\n",
    "        reward = 0\n",
    "        episode_end_flag = False\n",
    "        trial_count = 0\n",
    "\n",
    "        # episode loop\n",
    "        for episode in range(episode_num):\n",
    "            # choose initial action\n",
    "            self.state_function.reset_state()\n",
    "            state = self.observe_state()\n",
    "            action = self.act(state, update_flag)\n",
    "            \n",
    "            while episode_end_flag==False and (trial_count < maximum_trial_per_episode):\n",
    "                reward, state, action, episode_end_flag = self.learning_step(action)\n",
    "                trial_count += 1\n",
    "            else:\n",
    "                reward, episode_end_flag, trial_count = 0, False, 0\n",
    "\n",
    "        save_data = self.save() if save_flag else None\n",
    "        if reset_when_finished:\n",
    "            self.reset()\n",
    "\n",
    "        return save_data\n",
    "\n",
    "    def demo_play(self, episode_num=1, maximum_trial_per_episode=1000):\n",
    "        self.learn(episode_num, maximum_trial_per_episode, safe_flag=False, update_flag=False)\n",
    "\n",
    "\n",
    "    def save(self):\n",
    "        # returns (q_table, (action_count_list, total_play_count))\n",
    "        q_save_data = self.q_function.save_q_table()\n",
    "        policy_save_data = self.policy_function.save_record()\n",
    "        return q_save_data, policy_save_data\n",
    "\n",
    "    def load(self, q_save_data=None, policy_save_data=None):\n",
    "        if q_save_data is not None:\n",
    "            self.q_function.load_q_table(q_table)\n",
    "        if policy_save_data is not None:\n",
    "            self.policy_function.load_record(self, action_count_list=policy_save_data[0], \n",
    "                                             total_play_count=policy_save_data[1])\n",
    "\n",
    "    def reset(self, reset_q_table=True, reset_count=True, reset_last=True,\n",
    "              learning_rate=None, discount_rate=None,decay_learning_rate=None):\n",
    "        self.q_function.reset(reset_q_table, learning_rate, discount_rate, decay_learning_rate)\n",
    "        self.policy_function.reset_record(reset_count, reset_last)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q学習 : 方策オフ型TD制御\n",
    "SARSAでは次状態$s'$を観測した後に$Q$から導かれる方策により行動$a'$を選択したが、  \n",
    "Q学習では$\\max_{a'}Q(s',a')$を与える$a'$を用いる。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm\n",
    ">$Q(s,a)$を任意に初期化  \n",
    ">各エピソードに対して繰り返し：  \n",
    ">　　$s$を初期化    \n",
    ">　　エピソードの各ステップに対して繰り返し：  \n",
    ">　　　　$Q$から導かれる方策（εグリーディ方策など）を用いて、$s$で取る行動$a$を選択する  \n",
    ">　　　　行動$a$を取り、報酬$r$と次状態$s'$を観測する  \n",
    ">　　　　$Q(s,a) \\leftarrow Q(s,a) + \\alpha[r+\\gamma \\max_{a'} Q(s',a')-Q(s,a)]$  \n",
    ">　　　　$s \\leftarrow s';$  \n",
    ">　　$s$が終端状態ならば繰り返しを終了 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#from SARSA import Agent_SARSA, Q_table_function, Policy_e_greedy\n",
    "\n",
    "class Agent_Q_learning(Agent_SARSA):\n",
    "    def learning_step(self, action, update_flag=True):\n",
    "        reward, next_state, episode_end_flag = self.observe_state(action)\n",
    "        if episode_end_flag:\n",
    "            next_action = -1\n",
    "        else:\n",
    "            # choose a' which gives max Q(s',a')\n",
    "            next_action = self.act(next_state, update_flag, epsilon=0)\n",
    "        if update_flag:\n",
    "            self.q_function.update_q_table(reward, next_state, next_action,\n",
    "                                           self.last_state, self.last_action)\n",
    "        return reward, next_state, next_action, episode_end_flag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 性能比較"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 環境：FrozenLake  \n",
    "OpenAI Gym のFrozenLake-v0を一部改変したもの。  \n",
    "map_size = (横、縦)のサイズの環境があり、startから開始してgoalに移動することを目指す。  \n",
    "地面にはflat, start, goal, holeの４種類があり、  \n",
    "goalに移動した時に+1の報酬を、holeの場所に移動した場合は-1の報酬を得てエピソードが終了する。  \n",
    "  \n",
    "行動は0:上、1:右、2:下、3:左　の４種類。  \n",
    "ただし移動する際、slip_rateに等しい確率で進行方向とは90度曲がった方向へ進んでしまう。  \n",
    "また、マップ外へ移動しようとした時はその場でとどまる。  \n",
    "  \n",
    "hole_numの値域の範囲内で穴の個数が決まり、ランダムに配置される。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment_FrozenLake\n",
    "#   init()\n",
    "#       input : \n",
    "#           map_size=(width,height)     #\n",
    "#           slip_rate                   # Player will slip when move from \"F\" (Icey ground) according to slip_rate.\n",
    "#                                       #   (90 degrees curved from the direction which action you choosed)\n",
    "#           hole_num=(a,b)              # Number of Hole \"n\" will choose randomly, s.t. a<=n<=b\n",
    "#           start=(x,y), goal=(x,y)     # Start / Goal position, (right/down are positive direction)\n",
    "#           max_retry=(a,b)             # Maximum number of retry to generate map.\n",
    "#                                       #   a : max num to retry in the same hole_num.\n",
    "#                                       #      if retry_count > a,  hole_num is decremented.\n",
    "#                                       #   b : max num to decrement hole_num\n",
    "#           action                      # dictionary to definit action.\n",
    "#                                       #   For example, action[i]=(a,b) will change player's position\n",
    "#                                       #   from (x,y) to (x+a,y+b) (if it can be done)\n",
    "#           ground_name                 # dictionary to show map with Uppercase letter\n",
    "#\n",
    "#   return_next()\n",
    "#       input  : \n",
    "#           action\n",
    "#       output : \n",
    "#           reward                      # +1 (when reach to Goal), -1 (when reach to Hole)\n",
    "#           next_state                  # int n.  s.t. 0<=n<=(width*height)-1 \n",
    "#                                       #   When player is on (x,y), n= (y-1)*height + (x-1)\n",
    "#           episode_end_flag            # True when player move to Goal or Hole, False in other position.\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "class Environment_FrozenLake(object):\n",
    "    def __init__(self, map_size=(4,4), slip_rate=0.33, hole_num=(1,3), \n",
    "                 start=(1,1), goal=(-1,-1),max_retry=(10,10),\n",
    "                 reach_to_outside_map = False,\n",
    "                 action={0:(0,-1), 1:(1,0), 2:(0,1), 3:(-1,0)},\n",
    "                 ground_name={1:\"F\", 2:\"S\", 3:\"G\", 4:\"H\"}):\n",
    "        self.map_size = np.array(map_size)\n",
    "        self.slip_rate = slip_rate\n",
    "        self.hole_num = np.random.randint(hole_num[0], hole_num[1]+1)\n",
    "        self.start = np.array((start[0]-1, start[1]-1)) if min(start)>=1 else np.array((0,0))\n",
    "        self.goal = np.array((goal[0]-1, goal[1]-1)) if min(goal)>=1 else np.array(map_size)+np.array(goal)\n",
    "        self.max_retry = max_retry\n",
    "        self.reach_to_outside_map=False\n",
    "        self.action = action\n",
    "        self.ground_name = ground_name\n",
    "        self.ground_name[0] = \"N\"\n",
    "\n",
    "        self.player_position = np.array(self.start, dtype=int)\n",
    "        self.reward = 0\n",
    "        self.done=False\n",
    "        \n",
    "    def check_route(self, map_dup):\n",
    "        checkmap = copy.deepcopy(map_dup)\n",
    "        checkmap[(self.start[0],self.start[1])] = 1\n",
    "        checkmap[(self.goal[0],self.goal[1])] = 0\n",
    "        for i in range(self.map_size[0] * self.map_size[1]):\n",
    "            if (0 in checkmap)==False:\n",
    "                break\n",
    "            for h in range(self.map_size[1]):\n",
    "                for w in range(self.map_size[0]):\n",
    "                    if checkmap[h][w]==0: \n",
    "                        if checkmap[max(0,h-1)][w]==1 or checkmap[h][max(0,w-1)]==1 or \\\n",
    "                            checkmap[min(self.map_size[1]-1,h+1)][w]==1 or checkmap[h][min(self.map_size[0]-1,w+1)]==1:\n",
    "                            checkmap[h][w] = 1\n",
    "                            \n",
    "        # for debug\n",
    "        #print(\"checkmap, \", checkmap)\n",
    "        #can_reach=True\n",
    "                            \n",
    "        can_reach = True if checkmap[(self.goal[0],self.goal[1])]==1 else False\n",
    "        return can_reach\n",
    "                            \n",
    "    def generate_map(self, max_retry=None):\n",
    "        # 番号との対応は、１：氷、２：スタート地点、３：ゴール、４：穴\n",
    "        if (max_retry is None) or (min(max_retry) <= 0) or (max(max_retry) >= 256):\n",
    "            max_retry = self.max_retry\n",
    "        self.map = np.zeros(self.map_size, dtype=int)\n",
    "        self.map[(self.start[0],self.start[1])] = 2\n",
    "        self.map[(self.goal[0],self.goal[1])] = 3\n",
    "        retry_count = [0,0]\n",
    "        success_check = False\n",
    "        \n",
    "        # for debug\n",
    "        #print(\"start, goal = \", self.start, self.goal)\n",
    "        #print(\"generate_map, before, \\n\", self.map)\n",
    "                \n",
    "        while (retry_count[1] < max_retry[1]) and (success_check==False):\n",
    "            while (retry_count[0] < max_retry[0]) and (success_check==False):\n",
    "                map_dup = copy.deepcopy(self.map)\n",
    "                chip_index_list = np.where(self.map==0)\n",
    "                chip_index = np.random.choice(chip_index_list[0].size, self.hole_num, replace=False)\n",
    "                \n",
    "                for i in range(len(chip_index)):\n",
    "                    map_dup[chip_index_list[0][chip_index[i]]][chip_index_list[1][chip_index[i]]] = 4 \n",
    "                \n",
    "                retry_count[0] += 1\n",
    "                if self.check_route(map_dup):\n",
    "                    self.map = np.where(map_dup==4, map_dup, self.map)\n",
    "                    self.map = np.where(self.map==0, 1, self.map)\n",
    "                    success_check = True\n",
    "                    break\n",
    "            else:\n",
    "                self.hole_num = max(1, self.hole_num-1)\n",
    "                retry_count[1] += 1\n",
    "        return success_check\n",
    "\n",
    "    def show_map(self, raw_data=False, player_position=False, print_map=True, raw_array=False, end=\"\\n\"):\n",
    "        map_text = \"\"\n",
    "        output = \"\"\n",
    "        if raw_array:\n",
    "            return self.map\n",
    "        \n",
    "        for h in range(self.map_size[0]):\n",
    "            for w in range(self.map_size[1]):\n",
    "                map_text += self.ground_name[self.map[h][w]]\n",
    "                if w == self.map_size[1]-1:\n",
    "                    map_text += end\n",
    "        if raw_data:\n",
    "            output += str(self.map) + end\n",
    "        else:\n",
    "            output += map_text + end\n",
    "        if player_position:\n",
    "            output += \"player (x,y) = \" + str(self.player_position) + end\n",
    "        if print_map:\n",
    "            print(output)\n",
    "        else:\n",
    "            return output\n",
    "                \n",
    "    def return_next(self, action=None, render_flag=False):\n",
    "        if action is None:\n",
    "            return self.player_position[1] * self.map_size[0] + self.player_position[0]\n",
    "\n",
    "        # move direction\n",
    "        move_p = np.array(self.action[action]) # action={0:(0,-1), 1:(1,0), 2:(0,1), 3:(-1,0)} in default settings\n",
    "        slip_A, slip_B = move_p[::-1], move_p[::-1]*-1\n",
    "        \n",
    "        # for debug\n",
    "        #print(\"move, slip\", move_p, slip_A, slip_B)\n",
    "        #print(\"p\", [1-self.slip_rate, self.slip_rate/2, self.slip_rate/2])\n",
    "        \n",
    "        #move = np.random.choice([move_p, slip_A, slip_B],\n",
    "        #                        p=[1-self.slip_rate, self.slip_rate/2, self.slip_rate/2])\n",
    "        move = np.array([move_p, slip_A, slip_B])[np.random.choice(3, 1, p=[1-self.slip_rate, self.slip_rate/2, self.slip_rate/2])][0]\n",
    "        \n",
    "        # for debug\n",
    "        #print(self.player_position)\n",
    "        #print(move)\n",
    "        #print(\"max\", max(self.player_position[0]+move[0], 0))\n",
    "        \n",
    "        if self.reach_to_outside_map==False:\n",
    "            self.player_position[0] = min(max(self.player_position[0]+move[0], 0), self.map_size[0]-1)\n",
    "            self.player_position[1] = min(max(self.player_position[1]+move[1], 0), self.map_size[1]-1)\n",
    "        else:\n",
    "            self.player_position = self.player_position + move\n",
    "\n",
    "        # for debug\n",
    "        #print(\"self.player_position\", self.player_position)\n",
    "        #print(\"self.map_size\", self.map_size)\n",
    "        #print(\"self.player_position[0]\", self.player_position[0])\n",
    "        #print(\"self.map_size[0]\", self.map_size[0])\n",
    "        #print(\"map\\n\", self.map)\n",
    "        #print(\"self.map[(self.player_position[0], self.player_position[1])]\",\n",
    "        #      self.map[(self.player_position[0], self.player_position[1])])\n",
    "            \n",
    "            \n",
    "        # goal / hole check\n",
    "        if (self.player_position[0]<0) or (self.map_size[0]-1 < self.player_position[0]) \\\n",
    "            or (self.player_position[1]<0) or (self.map_size[1]-1 < self.player_position[1]): # Outside of map\n",
    "            self.reward = -1\n",
    "            self.done = True\n",
    "        elif self.map[(self.player_position[1], self.player_position[0])] == 4: # Hole\n",
    "            self.reward = -1\n",
    "            self.done = True\n",
    "        elif self.map[(self.player_position[1], self.player_position[0])] == 3: # Goal\n",
    "            self.reward = 1\n",
    "            self.done = True\n",
    "        else:\n",
    "            self.reward = 0\n",
    "            self.done = False\n",
    "            \n",
    "        next_state = self.player_position[1] * self.map_size[0] + self.player_position[0]\n",
    "\n",
    "        return self.reward, next_state, self.done\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.player_position = np.array(self.start, dtype=int)\n",
    "        self.reward, self.done = 0, False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2"
     ]
    }
   ],
   "source": [
    "# 表記更新テスト\n",
    "import sys, time\n",
    "for num, i in enumerate(range(3)):\n",
    "    sys.stdout.write(\"\\r%d\" % num)\n",
    "    sys.stdout.flush()\n",
    "    time.sleep(0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ToDo\n",
    "・マップとプレイヤーの位置を表示する（色付きがいい）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# それっぽい絵を表示する\n",
    "import sys, time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set color list\n",
    "color_list = {0:[128, 128, 128], #808080 , N\n",
    "              1:[240, 248, 255], #f0f8ff , F\n",
    "              2:[238, 238, 0],   #eeee00 , Start\n",
    "              3:[0, 238, 0],     #00ee00 , Goal\n",
    "              4:[178, 34, 34]}   #b22222 , Hole\n",
    "\n",
    "def show_grid_image(img_array, player_position,color, pause_time=.2):\n",
    "    arrays=[]\n",
    "    for y in range(imgf.shape[0]):\n",
    "        lines = []\n",
    "        for x in range(imgf.shape[1]):\n",
    "            lines.append(color_list[img[y][x]])\n",
    "        arrays.append(lines)\n",
    "    arrays = np.array(arrays, dtype=np.uint8)\n",
    "    plt.imshow(arrays)\n",
    "    plt.text(player_position[0]-0.1,player_position[1]+0.1,r'P',fontsize=20)\n",
    "    #plt.pause(0.2)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "text=\"\"\"\n",
    "img = np.array([[2,1,1,1],[1,1,4,1],[4,1,1,1],[1,1,1,3]])\n",
    "arrays=[]\n",
    "for y in range(imgf.shape[0]):\n",
    "    lines = []\n",
    "    for x in range(imgf.shape[1]):\n",
    "        lines.append(color_list[img[y][x]])\n",
    "    arrays.append(lines)\n",
    "arrays = np.array(arrays, dtype=np.uint8)\n",
    "plt.imshow(arrays)\n",
    "\n",
    "position = [1,1]\n",
    "plt.text(position[0]-1-0.1,position[1]-1+0.1,r'P',fontsize=20)\n",
    "\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAAD8CAYAAACPd+p5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBoWkpv8DgnM0a0KTWh8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faaa98fd710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAAD8CAYAAACPd+p5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQSGpyaCQ1GRQSGoyKCQ1GRSSmv4fi/dbcjOkXgsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faaa97ac6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAAD8CAYAAACPd+p5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADY1JREFUeJzt3X/sXfVdx/HnC+yCDLTZilJLgTnLDC5IoXYIOpENhYop\nfxAFI0yypI4xx4wkThfZFuPPPxYFFrDJiJDM4Qwbq1vnwgAHJOIoHatQfnWIUmwEulFoQLfi2z/u\ngXxXvt9+Cvf03O9tn4/kpuec++l5f27avHLv+fVOVSFJe3LQpCcgaf4zKCQ1GRSSmgwKSU0GhaQm\ng0JS0w+M85eTvAn4e+BY4HHg16rqO7OMexx4HngJ2FVVK8apK2lY436j+DBwa1UtA27t1ufyi1V1\noiEhTZ9xg2I1cH23fD1w7pj7kzQPZZwrM5M8W1ULu+UA33l5fbdx/w7sYPTT42+qau0e9rkGWANw\n6KGcfNxxr3t689dBJ096BhIA//kfj7P9mWfSGtc8RpHkq8CRs7z1kZkrVVVJ5kqdn6uqJ5P8CHBL\nkoeq6o7ZBnYhshZg+fLUbbe1Zjh9Djp0w6SnIAFw+ql7dySgGRRV9e653kvy30kWV9W2JIuBp+bY\nx5Pdn08l+TywEpg1KCTNP+Meo1gHvKdbfg/whd0HJHljksNfXgZ+Cbh/zLqSBjRuUPw5cGaSR4F3\nd+sk+bEk67sxPwrcleSbwNeBL1XVP41ZV9KAxrqOoqq2A++aZft/Aau65ceAnx6njqTJ8spMSU0G\nhaQmg0JSk0EhqcmgkNRkUEhqMigkNRkUkpoMCklNBoWkJoNCUpNBIanJoJDUZFBIajIoJDUZFJKa\nDApJTQaFpKZegiLJWUkeTrIlyau6hWXkyu79TUlO6qOupGGMHRRJDgY+CZwNHA9ckOT43YadDSzr\nXmuAa8atK2k4fXyjWAlsqarHquq7wI2MWg3OtBq4oUbuBhZ2fUAkTYE+gmIJ8MSM9a3dttc6RtI8\nNe8OZiZZk2RDkg3PPDPp2UiCfoLiSWDpjPWjum2vdQww6j1aVSuqasWiRT3MTtLY+giKe4BlSd6S\n5A3A+YxaDc60DrioO/txCrCjqrb1UFvSAMbqFAZQVbuSfAD4CnAwcF1VPZDkfd371wLrGXUO2wK8\nAFw8bl1Jwxk7KACqaj2jMJi57doZywVc2kctScObdwczJc0/BoWkJoNCUpNBIanJoJDUZFBIajIo\nJDUZFJKaDApJTQaFpCaDQlKTQSGpyaCQ1GRQSGoyKCQ1GRSSmgwKSU0GhaQmg0JS01C9R09PsiPJ\nfd3rij7qShrG2A/XndF79ExGHcDuSbKuqjbvNvTOqjpn3HqShtfHU7hf6T0KkOTl3qO7B8Vrd9DJ\nHHTohrF3I43rjuPfOukp7BM7t27dq3FD9R4FODXJpiRfTvJTc+1sZkvB7U8/3cP0JI1rqIOZG4Gj\nq+oE4Crg5rkGzmwp+OYjjhhoepL2ZJDeo1X1XFXt7JbXAwuS2FlUmhKD9B5NcmSSdMsru7rbe6gt\naQBD9R49D7gkyS7gReD8rs2gpCkwVO/Rq4Gr+6glaXhemSmpyaCQ1GRQSGoyKCQ1GRSSmgwKSU0G\nhaQmg0JSk0EhqcmgkNRkUEhqMigkNRkUkpoMCklNBoWkJoNCUpNBIanJoJDU1FdLweuSPJXk/jne\nT5Iru5aDm5Kc1EddScPo6xvF3wJn7eH9s4Fl3WsNcE1PdSUNoJegqKo7gG/vYchq4IYauRtYmGRx\nH7Ul7XtDHaPY27aDthSU5qF5dzDTloLS/DNUUDTbDkqav4YKinXARd3Zj1OAHVW1baDaksbUS6ew\nJJ8BTgcWJdkKfBRYAK90DFsPrAK2AC8AF/dRV9Iw+mopeEHj/QIu7aOWpOHNu4OZkuYfg0JSk0Eh\nqcmgkNRkUEhqMigkNRkUkpoMCklNBoWkJoNCUpNBIanJoJDUZFBIajIoJDUZFJKaDApJTQaFpCaD\nQlLTUC0FT0+yI8l93euKPupKGkYvz8xk1FLwauCGPYy5s6rO6amepAEN1VJQ0hTr6xvF3jg1ySZG\njX8ur6oHZhuUZA2jRsYsXXr0gNMbzh3Hv3XSU9hn3rn5W5Oewj6xv36uw05dsVfjhjqYuRE4uqpO\nAK4Cbp5roC0FpflnkKCoqueqame3vB5YkGTRELUljW+QoEhyZJJ0yyu7utuHqC1pfEO1FDwPuCTJ\nLuBF4Pyue5ikKTBUS8GrGZ0+lTSFvDJTUpNBIanJoJDUZFBIajIoJDUZFJKaDApJTQaFpCaDQlKT\nQSGpyaCQ1GRQSGoyKCQ1GRSSmgwKTY2Fh+T7Xm869GB+fMkifvWXz+Afbvy7SU9vvzbkw3WlXvz+\nRz4KwK7vfY9HHnmI9f/4Be782u18Y+MG/vQvPzHh2e2fDApNnT/4o4993/rXbruVc3/lTK656q/4\n7fd/kGOOPXYi89qf+dNDU+8XzngXx73tJ6kqvnHvPZOezn5p7KBIsjTJ7Uk2J3kgyWWzjEmSK5Ns\nSbIpyUnj1pVmevkRrN0znNWzPn567AJ+r6o2JjkcuDfJLVW1ecaYs4Fl3esdwDXdn9LY/vnWr/Lo\nIw+ThOUn/8ykp7NfGjsoqmobsK1bfj7Jg8ASYGZQrAZu6J68fXeShUkWd39Xek3+7I8/BowOZj76\n6MN8ad3NVBXv/+DvcvQxx0x2cvupXg9mJjkWWA78625vLQGemLG+tdv2qqA4EFoKajx/8ScfB0Y/\nM3544UJ+9rSf58Lfei+//hu/OeGZ7b96C4okhwE3AR+qqude736qai2wFmD5ySvs/aFXefZ//G8x\ntF7OeiRZwCgkPl1Vn5tlyJPA0hnrR3XbJE2BPs56BPgU8GBVzXW1yzrgou7sxynADo9PSNOjj58e\npwEXAv+W5L5u2x8CR8MrLQXXA6uALcALwMU91JU0kD7OetwF7PHkdXe249Jxa0maDK/MlNTkvR6a\nGp7tmBy/UUhqMigkNRkUkpoMCklNBoWkJoNCUpNBIanJoJDUZFBIajIoJDUZFJKaDApJTQaFpCaD\nQlKTQSGpyaCQ1DRUS8HTk+xIcl/3umLcupKGM1RLQYA7q+qcHupJGtjY3yiqaltVbeyWnwdebiko\naT8xVEtBgFOTbGLU+Ofyqnpgjn3s9y0F37n5W5OegvSa9HYws9FScCNwdFWdAFwF3DzXfqpqbVWt\nqKoVbz7iiL6mJ2kMg7QUrKrnqmpnt7weWJBkUR+1Je17g7QUTHJkN44kK7u628etLWkYQ7UUPA+4\nJMku4EXg/K57mKQpMFRLwauBq8etJWkyvDJTUpNBIanJoJDUZFBIajIoJDUZFJKaDApJTQaFpCaD\nQlKTQSGpyaCQ1GRQSGoyKCQ1GRSSmgwKSU0GhaQmg0JSk0EhqamPh+sekuTrSb7ZtRT8+CxjkuTK\nJFuSbEpy0rh1JQ2nj4fr/i9wRlXt7B7bf1eSL1fV3TPGnA0s617vAK7p/pQ0BfpoKVgv9+wAFnSv\n3Z+wvRq4oRt7N7AwyeJxa0saRl8NgA7uHtX/FHBLVe3eUnAJ8MSM9a3Yn1SaGr0ERVW9VFUnAkcB\nK5O8/fXuK8maJBuSbNj+9NN9TE/SmHo961FVzwK3A2ft9taTwNIZ60d122bbh71HpXmmj7MeRyRZ\n2C3/IHAm8NBuw9YBF3VnP04BdlTVtnFrSxpGH2c9FgPXJzmYUfB8tqq+mOR98EpLwfXAKmAL8AJw\ncQ91JQ2kj5aCm4Dls2y/dsZyAZeOW0vSZHhlpqQmg0JSk0EhqcmgkNRkUEhqMigkNRkUkpoMCklN\nBoWkJoNCUpNBIanJoJDUZFBIajIoJDUZFJKaDApJTQaFpCaDQlKTQSGpaajeo6cn2ZHkvu51xbh1\nJQ1nqN6jAHdW1Tk91JM0sD6ewl1Aq/eopCnWxzcKup4e9wI/AXxylt6jAKcm2cSoQ9jlVfXAHPta\nA6zpVncuPCQP9zHHvbAIeGagWkPyc02fIT/bMXszKKMvBP3oOoZ9Hvidqrp/xvYfAv6v+3myCvjr\nqlrWW+EeJNlQVSsmPY+++bmmz3z8bIP0Hq2q56pqZ7e8HliQZFGftSXtO4P0Hk1yZJJ0yyu7utvH\nrS1pGEP1Hj0PuCTJLuBF4Pzq8zdPP9ZOegL7iJ9r+sy7z9brMQpJ+yevzJTUZFBIajrggyLJWUke\nTrIlyYcnPZ++JLkuyVNJ7m+Pnh5Jlia5Pcnm7paByyY9pz7sza0Qk3RAH6PoDsA+wuhMzVbgHuCC\nqto80Yn1IMk7GV0xe0NVvX3S8+lLksXA4qramORwRhf6nTvt/2bdWcE3zrwVArhsllshJuJA/0ax\nEthSVY9V1XeBG4HVE55TL6rqDuDbk55H36pqW1Vt7JafBx4Elkx2VuOrkXl7K8SBHhRLgCdmrG9l\nP/hPd6BIciywHJjtloGpk+TgJPcBTwG3zHErxEQc6EGhKZXkMOAm4ENV9dyk59OHqnqpqk4EjgJW\nJpk3PxkP9KB4Elg6Y/2obpvmse43/E3Ap6vqc5OeT9/muhVikg70oLgHWJbkLUneAJwPrJvwnLQH\n3UG/TwEPVtUnJj2fvuzNrRCTdEAHRVXtAj4AfIXRQbHPznX7+7RJ8hngX4C3Jdma5L2TnlNPTgMu\nBM6Y8cS0VZOeVA8WA7d3j2K4h9Exii9OeE6vOKBPj0raOwf0NwpJe8egkNRkUEhqMigkNRkUkpoM\nCklNBoWkpv8HIrFGvj0ovXoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faab308b438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAAD8CAYAAACPd+p5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCklNBoWkpv8HIrFGvj0ovXoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faab30fdb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAAD8CAYAAACPd+p5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADZlJREFUeJzt3X/sXfVdx/HnC+yCDLSZRamlhTnLDC5IAQuCTmRDB2Lg\nD6JghEmWNEOmTF3i4hLmYvz5xxIZC5NkREjm5gwbq1vnwoANiOIoXVeh/OoQpdgIdKOsAdmKb/+4\nB/Jd+X75FO7puff2+3wkN99z7v1w3p+bklfOPb/eqSok6ZUcNOkJSJp+BoWkJoNCUpNBIanJoJDU\nZFBIavqBcf7jJG8A/gE4BngU+PWq+vY84x4FvgO8AOypqpPHqStpWOPuUbwfuKWqVgO3dOsL+aWq\nOsGQkGbPuEFxHnB9t3w9cP6Y25M0hTLOlZlJnq6qpd1ygG+/uL7XuP8AdjH66fG3VXXtK2xzHbAO\n4NBDOenYY1/z9KbXQSdNegYSAP/1n4+y86mn0hrXPEaR5MvAkfN89IG5K1VVSRZKnZ+vqseT/Chw\nc5IHqur2+QZ2IXItwJo1qVtvbc1w9hx06MZJT0EC4IzT9u1IQDMoqurtC32W5H+SLK+qHUmWA08s\nsI3Hu79PJPkssBaYNygkTZ9xj1GsB97ZLb8T+NzeA5K8PsnhLy4DvwzcO2ZdSQMaNyj+EjgrycPA\n27t1kvx4kg3dmB8D7kzyDeBrwBeq6p/HrCtpQGNdR1FVO4G3zfP+fwPndMuPAD8zTh1Jk+WVmZKa\nDApJTQaFpCaDQlKTQSGpyaCQ1GRQSGoyKCQ1GRSSmgwKSU0GhaQmg0JSk0EhqcmgkNRkUEhqMigk\nNRkUkpoMCklNvQRFknckeTDJtiQv6xaWkau6z7ckObGPupKGMXZQJDkY+ChwNnAccFGS4/Yadjaw\nunutA64Zt66k4fSxR7EW2FZVj1TVd4FPMWo1ONd5wA01chewtOsDImkG9BEUK4DH5qxv7957tWMk\nTampO5iZZF2SjUk2PvXUpGcjCfoJiseBlXPWj+ree7VjgFHv0ao6uapOXrash9lJGlsfQXE3sDrJ\nG5O8DriQUavBudYDl3RnP04FdlXVjh5qSxrAWJ3CAKpqT5L3AF8CDgauq6r7kry7+/xjwAZGncO2\nAc8Cl45bV9Jwxg4KgKrawCgM5r73sTnLBVzeRy1Jw5u6g5mSpo9BIanJoJDUZFBIajIoJDUZFJKa\nDApJTQaFpCaDQlKTQSGpyaCQ1GRQSGoyKCQ1GRSSmgwKSU0GhaQmg0JSk0EhqcmgkNQ0VO/RM5Ls\nSrK5e13ZR11Jwxj74bpzeo+exagD2N1J1lfV1r2G3lFV545bT9Lw+ngK90u9RwGSvNh7dO+gePUO\nOomDDt049makcd1+3JsmPYX9Yvf27fs0bqjeowCnJdmS5ItJfnqhjc1tKbjzySd7mJ6kcQ11MHMT\nsKqqjgc+Aty00MC5LQV/5IgjBpqepFcySO/RqnqmqnZ3yxuAJUnsLCrNiEF6jyY5Mkm65bVd3Z09\n1JY0gKF6j14AXJZkD/AccGHXZlDSDBiq9+jVwNV91JI0PK/MlNRkUEhqMigkNRkUkpoMCklNBoWk\nJoNCUpNBIanJoJDUZFBIajIoJDUZFJKaDApJTQbFAWjpIfm+1xsOPZifWLGMX/uVM/nHT/39pKen\nGdTLbeaaTn/0gQ8CsOd73+Ohhx5gwz99jju+ehtf37SRP//rD094dpolmebnx6w56eT6yr/4FO5X\na+khAeDp//3+f9uv3noL5//qWQBsvv8Rjj7mmKGnNrMO1Kdw/8H27Tz8/PNpjfOnxyLyi2e+jWPf\n/FNUFV+/5+5JT0czxKBYZF7cg+weYSrtk75aCl6X5Ikk9y7weZJc1bUc3JLkxD7q6tX5yi1f5uGH\nHiQJa0762UlPRzOkr4OZf8fomZg3LPD52cDq7nUKcE33V/vRX/zpnwCjg5kPP/wgX1h/E1XF7/ze\n77Pq6KMnOznNlL4ernt7kmNeYch5wA3dk7fvSrI0yfKq2tFHfc3vr/7sQ8DoZ8YPL13Kz53+C1z8\n2+/iN37ztyY8M82aoU6PLtR28GVBkWQdsA5g5cpVg0zuQLX3WQ/ptZq6g5m2FJSmz1BB0Ww7KGl6\nDRUU64FLurMfpwK7PD4hzY5ejlEk+SRwBrAsyXbgg8ASeKlj2AbgHGAb8CxwaR91JQ2jr7MeFzU+\nL+DyPmpJGp43hR2APNuhvk3dWQ9J08egkNRkUEhqMigkNRkUkpoMCklNBoWkJoNCUpNBIanJoJDU\nZFBIajIoJDUZFJKaDApJTQaFpCaDQlKTQSGpaaiWgmck2ZVkc/e6so+6koYxVEtBgDuq6tye6kka\nUC97FFV1O/CtPrYlafoM+XDd05JsYdT4531Vdd98gxZDS8Hbj3vTpKew37x16zcnPYX94kD9Xoed\ndvI+jRvqYOYmYFVVHQ98BLhpoYG2FJSmzyBBUVXPVNXubnkDsCTJsiFqSxrfIEGR5Mgk6ZbXdnV3\nDlFb0viGail4AXBZkj3Ac8CFXfcwSTNgqJaCVzM6fSppBnllpqQmg0JSk0EhqcmgkNRkUEhqMigk\nNRkUkpoMCklNBoWkJoNCUpNBIanJoJDUZFBIajIoJDUZFJKaDApJTQaFpCaDQlLT2EGRZGWS25Js\nTXJfkivmGZMkVyXZlmRLkhPHrStpOH08M3MP8IdVtSnJ4cA9SW6uqq1zxpwNrO5epwDXdH8lzYCx\n9yiqakdVbeqWvwPcD6zYa9h5wA01chewNMnycWtLGkavxyiSHAOsAf5tr49WAI/NWd/Oy8PkxW2s\nS7IxycadTz7Z5/QkvUa9BUWSw4AbgfdW1TOvdTu2FJSmTy9BkWQJo5D4RFV9Zp4hjwMr56wf1b0n\naQb0cdYjwMeB+6vqwwsMWw9c0p39OBXYVVU7xq0taRh9nPU4HbgY+Pckm7v3/hhYBS+1FNwAnANs\nA54FLu2hrqSBjB0UVXUnkMaYAi4ft5akyfDKTElNBoWkJoNCUpNBIanJoJDUZFBIajIoJDUZFJKa\nDApJTQaFpCaDQlKTQSGpyaCQ1GRQSGoyKCQ1GRSSmgwKSU0GhaSmoVoKnpFkV5LN3evKcetKGs5Q\nLQUB7qiqc3uoJ2lgQ7UUlDTD+tijeMkrtBQEOC3JFkaNf95XVfctsI11wDqAlStX9Tm9qfHWrd+c\n9BSkV2WoloKbgFVVdTzwEeCmhbZjS0Fp+gzSUrCqnqmq3d3yBmBJkmV91Ja0/w3SUjDJkd04kqzt\n6u4ct7akYQzVUvAC4LIke4DngAu77mGSZsBQLQWvBq4et5akyfDKTElNBoWkJoNCUpNBIanJoJDU\nZFBIajIoJDUZFJKaDApJTQaFpCaDQlKTQSGpyaCQ1GRQSGoyKCQ1GRSSmgwKSU0GhaSmPh6ue0iS\nryX5RtdS8EPzjEmSq5JsS7IlyYnj1pU0nD4ervs8cGZV7e4e239nki9W1V1zxpwNrO5epwDXdH8l\nzYA+WgrWiz07gCXda+8nbJ8H3NCNvQtYmmT5uLUlDaOvBkAHd4/qfwK4uar2bim4Anhszvp27E8q\nzYxegqKqXqiqE4CjgLVJ3vJat5VkXZKNSTbufPLJPqYnaUy9nvWoqqeB24B37PXR48DKOetHde/N\ntw17j0pTpo+zHkckWdot/yBwFvDAXsPWA5d0Zz9OBXZV1Y5xa0saRh9nPZYD1yc5mFHwfLqqPp/k\n3fBSS8ENwDnANuBZ4NIe6koaSB8tBbcAa+Z5/2Nzlgu4fNxakibDKzMlNRkUkpoMCklNBoWkJoNC\nUpNBIanJoJDUZFBIajIoJDUZFJKaDApJTQaFpCaDQlKTQSGpyaCQ1GRQSGoyKCQ1GRSSmgwKSU1D\n9R49I8muJJu715Xj1pU0nKF6jwLcUVXn9lBP0sD6eAp3Aa3eo5JmWB97FHQ9Pe4BfhL46Dy9RwFO\nS7KFUYew91XVfQtsax2wrlvdvfSQPNjHHPfBMuCpgWoNye81e4b8bkfvy6CMdgj60XUM+yzwu1V1\n75z3fwj4v+7nyTnA31TV6t4K9yDJxqo6edLz6Jvfa/ZM43cbpPdoVT1TVbu75Q3AkiTL+qwtaf8Z\npPdokiOTpFte29XdOW5tScMYqvfoBcBlSfYAzwEXVp+/efpx7aQnsJ/4vWbP1H23Xo9RSDoweWWm\npCaDQlLTog+KJO9I8mCSbUneP+n59CXJdUmeSHJve/TsSLIyyW1Jtna3DFwx6Tn1YV9uhZikRX2M\nojsA+xCjMzXbgbuBi6pq60Qn1oMkb2V0xewNVfWWSc+nL0mWA8uralOSwxld6Hf+rP+bdWcFXz/3\nVgjginluhZiIxb5HsRbYVlWPVNV3gU8B5014Tr2oqtuBb016Hn2rqh1Vtalb/g5wP7BisrMaX41M\n7a0Qiz0oVgCPzVnfzgHwP91ikeQYYA0w3y0DMyfJwUk2A08ANy9wK8RELPag0IxKchhwI/Deqnpm\n0vPpQ1W9UFUnAEcBa5NMzU/GxR4UjwMr56wf1b2nKdb9hr8R+ERVfWbS8+nbQrdCTNJiD4q7gdVJ\n3pjkdcCFwPoJz0mvoDvo93Hg/qr68KTn05d9uRVikhZ1UFTVHuA9wJcYHRT79EK3v8+aJJ8E/hV4\nc5LtSd416Tn15HTgYuDMOU9MO2fSk+rBcuC27lEMdzM6RvH5Cc/pJYv69KikfbOo9ygk7RuDQlKT\nQSGpyaCQ1GRQSGoyKCQ1GRSSmv4fi/dbcjOkXgsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faab318bdd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAAD8CAYAAACPd+p5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADVFJREFUeJzt3X+o3fV9x/HnKy6ls7oGFzez/JilSwdanL+INh3WdXWo\nCJYSJEK1yCCt2GFhUmQDx/4oSP8oTC06oTKF0q5g60IbV1xra4S5mqY201g17dyMkyXGNjEoG3Hv\n/XG+kbvbe/O59XzzPed6nw843O/3nE++789BefE931/vVBWSdCzLJj0BSdPPoJDUZFBIajIoJDUZ\nFJKaDApJTb82zj9Ocgrw98DpwPPAVVX18znGPQ+8CrwBHKmq88epK2lY4+5R3Ax8p6rWA9/p1ufz\nR1V1tiEhLT7jBsWVwL3d8r3AR8fcnqQplHGuzEzyi6pa0S0H+PnR9Vnj/g04yOinx99W1d3H2OYW\nYAvAiSdy3vve95anN72WnTfpGUgA/Me/P8+Bl19Oa1zzGEWSfwJOm+Ojv5y5UlWVZL7U+cOqejHJ\nbwEPJflJVT0y18AuRO4GOOec1He/25rh4rPsxB2TnoIEwMUbF3YkoBkUVfWR+T5L8l9JVlXVS0lW\nAfvm2caL3d99Sb4BbADmDApJ02fcYxRbgU90y58A/mH2gCTvSnLy0WXgT4Anx6wraUDjBsWtwCVJ\nngM+0q2T5HeSbOvG/DbwaJIfAz8AvlVV/zhmXUkDGus6iqo6APzxHO//J3B5t/wz4A/GqSNpsrwy\nU1KTQSGpyaCQ1GRQSGoyKCQ1GRSSmgwKSU0GhaQmg0JSk0EhqcmgkNRkUEhqMigkNRkUkprGus18\nMTvllP+/vmwZrFgBZ54J11wDmzZNZl7SNFqyQXHUZz87+nvkCDz7LDz4IGzfDj/6EXzuc5OdmzQt\nlnxQ3DyrE8n3vw8f+xjcdRd88pOwbt1k5iVNE49RzPKhD8H69VAFO3dOejbSdOglKJJcmuSZJHuS\n/FK3sIzc1n2+K8m5fdQ9Xo62Okmz24G0NIwdFElOAL4IXAacAVyd5IxZwy4D1nevLcCd49Y9Xr73\nPdizZxQS5051nEnD6eMYxQZgT/cQXZJ8lVGrwd0zxlwJ3FejtmSPJVlxtB9ID/XHcuuto79HjsBz\nz8G2baM9iuuvh7VrJzs3aVr0ERSrgRdmrO8FLljAmNXAxIPi858f/U3g3e+GD3wAPv5xuOqqyc5L\nmiZTd9ZjZu/RNWuOf71XXjn+NaTFro+DmS8CM3fS13Tv/apjgFHv0ao6v6rOX7myh9lJGlsfQfE4\nsD7Je5K8A9jMqNXgTFuBa7uzHxcCB6fh+ISkhRn7p0dVHUnyaeDbwAnAPVX1VJJPdZ/fBWxj1Dls\nD/AacN24dSUNp5djFFW1jVEYzHzvrhnLBdzQRy1Jw/PKTElNU3fWYyie7ZAWzj0KSU0GhaQmg0JS\nk0EhqcmgkNRkUEhqMigkNRkUkpoMCklNBoWkJoNCUpNBIanJoJDUZFBIajIoJDUZFJKaDApJTUP1\nHr04ycEkT3SvW/qoK2kYYz8Kb0bv0UsYdQB7PMnWqto9a+j2qrpi3HqShjdU79G3Ztl5LDtxx9ib\nkcb1yBnvnfQUjovDe/cuaFwfPz3m6ys628Yku5I8mOTM+TaWZEuSHUl2HNi/v4fpSRrXUAczdwLr\nquos4HbggfkGzmwp+JunnjrQ9CQdyyC9R6vqUFUd7pa3AcuT2FlUWiQG6T2a5LQk6ZY3dHUP9FBb\n0gCG6j26Cbg+yRHgdWBz12ZQ0iIwVO/RO4A7+qglaXhemSmpyaCQ1GRQSGoyKCQ1GRSSmgwKSU0G\nhaQmg0JSk0EhqcmgkNRkUEhqMigkNRkUkpoMCklNBoWkJoNCUpNBIanJoJDU1FdLwXuS7Evy5Dyf\nJ8ltXcvBXUnO7aOupGH0tUfxd8Clx/j8MmB999oC3NlTXUkD6CUoquoR4JVjDLkSuK9GHgNWJFnV\nR21Jx99QxygW2nbQloLSFJq6g5m2FJSmz1BB0Ww7KGl6DRUUW4Fru7MfFwIHq+qlgWpLGlMvncKS\nfAW4GFiZZC/wV8ByeLNj2DbgcmAP8BpwXR91JQ2jr5aCVzc+L+CGPmpJGt7UHcyUNH0MCklNBoWk\nJoNCUpNBIanJoJDUZFBIajIoJDUZFJKaDApJTQaFpCaDQlKTQSGpyaCQ1GRQSGoyKCQ1GRSSmgwK\nSU1DtRS8OMnBJE90r1v6qCtpGL08M5NRS8E7gPuOMWZ7VV3RUz1JAxqqpaCkRayvPYqF2JhkF6PG\nPzdV1VNzDUqyhVEjY9auXTfg9IbzyBnvnfQUjpuLdv900lM4Lt6u3+ukjecvaNxQBzN3Auuq6izg\nduCB+QbaUlCaPoMERVUdqqrD3fI2YHmSlUPUljS+QYIiyWlJ0i1v6OoeGKK2pPEN1VJwE3B9kiPA\n68DmrnuYpEVgqJaCdzA6fSppEfLKTElNBoWkJoNCUpNBIanJoJDUZFBIajIoJDUZFJKaDApJTQaF\npCaDQlKTQSGpyaCQ1GRQSGoyKCQ1GRSSmgwKSU0GhaSmsYMiydokDyfZneSpJDfOMSZJbkuyJ8mu\nJOeOW1fScPp4ZuYR4M+rameSk4EfJnmoqnbPGHMZsL57XQDc2f2VtAiMvUdRVS9V1c5u+VXgaWD1\nrGFXAvfVyGPAiiSrxq0taRi9HqNIcjpwDvAvsz5aDbwwY30vvxwmR7exJcmOJDsO7N/f5/QkvUW9\nBUWSk4D7gc9U1aG3uh1bCkrTp5egSLKcUUh8uaq+PseQF4G1M9bXdO9JWgT6OOsR4EvA01X1hXmG\nbQWu7c5+XAgcrKqXxq0taRh9nPX4IHAN8K9Jnuje+wtgHbzZUnAbcDmwB3gNuK6HupIGMnZQVNWj\nQBpjCrhh3FqSJsMrMyU1GRSSmgwKSU0GhaQmg0JSk0EhqcmgkNRkUEhqMigkNRkUkpoMCklNBoWk\nJoNCUpNBIanJoJDUZFBIajIoJDUZFJKahmopeHGSg0me6F63jFtX0nCGaikIsL2qruihnqSBDdVS\nUNIi1scexZuO0VIQYGOSXYwa/9xUVU/Ns40twBaAtWvX9Tm9qXHR7p9OegrSr2SoloI7gXVVdRZw\nO/DAfNuxpaA0fQZpKVhVh6rqcLe8DVieZGUftSUdf4O0FExyWjeOJBu6ugfGrS1pGEO1FNwEXJ/k\nCPA6sLnrHiZpERiqpeAdwB3j1pI0GV6ZKanJoJDUZFBIajIoJDUZFJKaDApJTQaFpCaDQlKTQSGp\nyaCQ1GRQSGoyKCQ1GRSSmgwKSU0GhaQmg0JSk0EhqcmgkNTUx8N135nkB0l+3LUU/Os5xiTJbUn2\nJNmV5Nxx60oaTh8P1/1v4MNVdbh7bP+jSR6sqsdmjLkMWN+9LgDu7P5KWgT6aClYR3t2AMu71+wn\nbF8J3NeNfQxYkWTVuLUlDaOvBkAndI/q3wc8VFWzWwquBl6Ysb4X+5NKi0YvQVFVb1TV2cAaYEOS\n97/VbSXZkmRHkh0H9u/vY3qSxtTrWY+q+gXwMHDprI9eBNbOWF/TvTfXNuw9Kk2ZPs56nJpkRbf8\n68AlwE9mDdsKXNud/bgQOFhVL41bW9Iw+jjrsQq4N8kJjILna1X1zSSfgjdbCm4DLgf2AK8B1/VQ\nV9JA+mgpuAs4Z47375qxXMAN49aSNBlemSmpyaCQ1GRQSGoyKCQ1GRSSmgwKSU0GhaQmg0JSk0Eh\nqcmgkNRkUEhqMigkNRkUkpoMCklNBoWkJoNCUpNBIanJoJDUZFBIahqq9+jFSQ4meaJ73TJuXUnD\nGar3KMD2qrqih3qSBtbHU7gLaPUelbSI9bFHQdfT44fA7wFfnKP3KMDGJLsYdQi7qaqemmdbW4At\n3erhFe/MM33McQFWAi8PVGtIfq/FZ8jv9rsLGZTRDkE/uo5h3wD+rKqenPH+bwD/2/08uRz4m6pa\n31vhHiTZUVXnT3oeffN7LT7T+N0G6T1aVYeq6nC3vA1YnmRln7UlHT+D9B5NclqSdMsburoHxq0t\naRhD9R7dBFyf5AjwOrC5+vzN04+7Jz2B48TvtfhM3Xfr9RiFpLcnr8yU1GRQSGpa8kGR5NIkzyTZ\nk+TmSc+nL0nuSbIvyZPt0YtHkrVJHk6yu7tl4MZJz6kPC7kVYpKW9DGK7gDss4zO1OwFHgeurqrd\nE51YD5JcxOiK2fuq6v2Tnk9fkqwCVlXVziQnM7rQ76OL/b9Zd1bwXTNvhQBunONWiIlY6nsUG4A9\nVfWzqvof4KvAlROeUy+q6hHglUnPo29V9VJV7eyWXwWeBlZPdlbjq5GpvRViqQfFauCFGet7eRv8\nT7dUJDkdOAeY65aBRSfJCUmeAPYBD81zK8RELPWg0CKV5CTgfuAzVXVo0vPpQ1W9UVVnA2uADUmm\n5ifjUg+KF4G1M9bXdO9pinW/4e8HvlxVX5/0fPo2360Qk7TUg+JxYH2S9yR5B7AZ2DrhOekYuoN+\nXwKerqovTHo+fVnIrRCTtKSDoqqOAJ8Gvs3ooNjX5rv9fbFJ8hXgn4HfT7I3yZ9Oek49+SBwDfDh\nGU9Mu3zSk+rBKuDh7lEMjzM6RvHNCc/pTUv69KikhVnSexSSFsagkNRkUEhqMigkNRkUkpoMCklN\nBoWkpv8DgnM0a0KTWh8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faaa9b73390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAAD8CAYAAACPd+p5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBoWkpv8DgnM0a0KTWh8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faaa9687400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAAD8CAYAAACPd+p5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBoWkpv8DgnM0a0KTWh8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faaa9386160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAAD8CAYAAACPd+p5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQSGpyaCQ1GRQSGoyKCQ1GRSSmv4fi/dbcjOkXgsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faaa97c0d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAAD8CAYAAACPd+p5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBoWkpv8DgnM0a0KTWh8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faaa993bc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys, time\n",
    "import numpy as np\n",
    "\n",
    "an = Environment_FrozenLake(map_size=(5,5))\n",
    "an.generate_map()\n",
    "\n",
    "for i in enumerate(range(10)):\n",
    "    if i == 0:\n",
    "        img = an.show_map(raw_array=True)\n",
    "        show_grid_image(img_array=img, player_position=(state%4, int(state/4)),color=color_list)\n",
    "        time.sleep(0.2)\n",
    "    action = np.random.randint(0,4)\n",
    "    reward, state, done = an.return_next(action)\n",
    "    img = an.show_map(raw_array=True)\n",
    "    show_grid_image(img_array=img, player_position=(state%4, int(state/4)),color=color_list)\n",
    "    time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SFFFFFFFFFFHFFFFFFFFFFFFGplayer (x,y) = [1 0]\n",
      "SFFFFFFFFFFHFFFFFFFFFFFFGplayer (x,y) = [1 0]\n",
      "SFFFFFFFFFFHFFFFFFFFFFFFGplayer (x,y) = [1 0]\n",
      "SFFFFFFFFFFHFFFFFFFFFFFFGplayer (x,y) = [2 0]\n",
      "SFFFFFFFFFFHFFFFFFFFFFFFGplayer (x,y) = [3 0]\n",
      "SFFFFFFFFFFHFFFFFFFFFFFFGplayer (x,y) = [3 1]\n",
      "SFFFFFFFFFFHFFFFFFFFFFFFGplayer (x,y) = [3 0]\n",
      "SFFFFFFFFFFHFFFFFFFFFFFFGplayer (x,y) = [2 0]\n",
      "SFFFFFFFFFFHFFFFFFFFFFFFGplayer (x,y) = [1 0]\n",
      "SFFFFFFFFFFHFFFFFFFFFFFFGplayer (x,y) = [0 0]\n",
      "pop"
     ]
    }
   ],
   "source": [
    "import sys, time\n",
    "import numpy as np\n",
    "\n",
    "an = Environment_FrozenLake(map_size=(5,5))\n",
    "an.generate_map()\n",
    "\n",
    "for num, i in enumerate(range(10)):\n",
    "    action = np.random.randint(0,4)\n",
    "    an.return_next(action)\n",
    "    text = an.show_map(False, True, print_map=False, end=\"\")\n",
    "    sys.stdout.write(\"\\r\"+text+\"\\n\")\n",
    "    sys.stdout.flush()\n",
    "    sys.stdout.write(\"\\r\"+\"pop\")\n",
    "    time.sleep(0.2)\n",
    "    \n",
    "    \n",
    "    #print(\"text, \\n\", text)\n",
    "    #sys.stdout.write(\"\\r\" + text)\n",
    "    \n",
    "    #sys.stdout.write(\"\\r%d\" % num)\n",
    "    #sys.stdout.flush()\n",
    "    #time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SFFF\n",
      "FFHF\n",
      "HFHF\n",
      "FFFG\n",
      "\n",
      "\n",
      "[[2 1 1 1]\n",
      " [1 1 4 1]\n",
      " [4 1 4 1]\n",
      " [1 1 1 3]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "an = Environment_FrozenLake(map_size=(4,4), slip_rate=0.33, hole_num=(3,3))\n",
    "an.generate_map()\n",
    "an.show_map(raw_data=False)\n",
    "an.show_map(raw_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d'"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=\"abcde\"\n",
    "a[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "result,  (0, 1, False)\n",
      "[[2 1 1 1]\n",
      " [1 1 1 1]\n",
      " [4 1 1 1]\n",
      " [1 4 4 3]]\n",
      "player (x,y) =  [1 0]\n"
     ]
    }
   ],
   "source": [
    "print(an.return_next())\n",
    "print(\"result, \", an.return_next(2))\n",
    "\n",
    "#an.show_map()\n",
    "an.show_map(True, True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.array([1,2])\n",
    "#b[0]\n",
    "max(b[0]+b[0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "[[1 2]\n",
      " [3 8]]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "a = np.array([[1,2],[3,4]])\n",
    "b = copy.deepcopy(a)\n",
    "b[(1,1)]=8\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "c = True if b[(1,1)]==8 else False\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2]\n",
      "[1 1]\n",
      "[-1 -1]\n",
      "[2 1]\n"
     ]
    }
   ],
   "source": [
    "a = np.array((1,2))\n",
    "b = (0,-1)\n",
    "\n",
    "c = (a+b)*-1\n",
    "d = a[::-1]\n",
    "\n",
    "print(a)\n",
    "print(a+b)\n",
    "print(c)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3, 3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=(1,2)\n",
    "b=(3,3)\n",
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.array((2,5))\n",
    "b=np.array((3,1))\n",
    "np.max((a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n\n",
      "nn\n"
     ]
    }
   ],
   "source": [
    "def aa(a=None):\n",
    "    if a is None:\n",
    "        print(\"n\")\n",
    "        return \"nn\"\n",
    "    \n",
    "    print(\"y\")\n",
    "    return 1\n",
    "\n",
    "b = aa(a=None)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
